---
title: "SeaScape_Timelines"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libs, message = FALSE, warning=FALSE}
library(dplyr)
library(tidyverse)

library(scales)

library(akima)
#library(asbio)
#library(tmap)         # raster + vector layers
#library(raster)       # Main raster library
#library(tidyverse)    # our old friend
#library(sf)           # to work with simple features data
#library(mapview)
library(openxlsx)
library(class)
library(RANN)
library("survival")
library("Hmisc")

library(MARSS)
library(utils)


#install.packages("survival")

library(lattice)
#install.packages("latticeExtra")


library(survival)
library(Hmisc)
library(lubridate)
#install.packages("installr")
#library(installr)
```
## Importing and Tidying GC Image Data
Background: GC image pre-processing
- All images must be RI configured and searched against 1) a custom library of internal standard compounds 2) a custom library of field blank compounds 3) one or more custom libraries of template compounds to be traced over campaign.  Libraries need not be compiled into one and can remain separated by source file. 
- Note: manually checking for appropriate internal standard assignments strongly advised

Required files:
- Blob table summary.  See example for formatting; match exactly to avoid bugs. Note: if GCxGC file name convention differs from that in example blob table summary, adjust the date and file parsing code accordingly
- Folder with all blob tables to be parsed
- all blob tables from pre-processed GC image files in csv format
```{r timeline_import, message=FALSE, warning=FALSE}
bt_sum_bloom3 <- read_csv("Read_Files/Blob_table_summary_CAICESample.csv") %>% 
  filter(Bloom == 3)

bt_sum_bloom <- read_csv("Read_Files/Blob_table_summary_CAICESample.csv") %>% 
  filter(Category == "Sample")

bt_sum_bloom3 <- bt_sum_bloom3 %>% mutate(r_date =    mdy_hm(SS_startdate)) %>% 
  mutate(run_date = as.Date(gsub("GCxGC_","",File_num), "%Y%m%d"))

make_file_name <- function(date_string) {
  file_start <- "Read_Files/CAICE_blobtables/"
  file_end <- ".h5_img01_Blob_Table.csv"
  full_name <- paste(file_start,date_string,file_end, sep = "")
  return(full_name)
  
}

read_bt_files <- function(fi_name_short) {
  
  fi_name <- make_file_name(fi_name_short)
  temp_bt <<- read_csv(file = fi_name)
  temp_bt <- temp_bt %>% mutate(File_num = fi_name_short)
  temp_bt <<- temp_bt
  return(temp_bt)
}

make_massive_table <- function(summary_table){
 
  M <- read_bt_files(as.character(summary_table$File_num[1]))

  for(i in 2:length(summary_table$File_num)){
    t <- read_bt_files(as.character(summary_table$File_num[i]))
    Mnew <- rbind(M, t)
    M <- Mnew
    print(i)
  }
  M_t <<- M
}

make_massive_table(bt_sum_bloom3)


M_t_full3 <- M_t %>% 
  left_join(bt_sum_bloom3, by = "File_num") %>% 
  mutate(Punch_t_norm_vol = Volume/Punch_num_sample_time_norm)

names(M_t_full3) <- make.names(names(M_t_full3),unique = TRUE) 

make_massive_table(bt_sum_bloom)


M_t_full <- M_t %>% 
  left_join(bt_sum_bloom, by = "File_num") %>% 
  mutate(Punch_t_norm_vol = Volume/Punch_num_sample_time_norm)

names(M_t_full) <- make.names(names(M_t_full),unique = TRUE) 

btz1 <- M_t_full3 %>% 
  filter(Compound.Name == "20200803_1535_blob_958_")
# its here

```

condensing to unique points

```{r, message=FALSE, warning=FALSE}
Match_factor_floor <- 750
Reverse_match_factor_floor <- 100
LRI_diff_floor <- 6




fb_match_factor_floor <- 600
fb_reverse_match_factor_floor <- 100
IS_lib_name <- "caice_ssi"
lib_remove_1 <- "caice_ssa_0805_0612"
lib_remove_2 <- "caice_ssa_0803_1728"
lib_remove_3 <- "caice_ssa_0803_oil_1728"
lib_remove_4 <- "amzi0503_b"
#FB_lib_name <- "amz_fb_trimmed_esrem"

rt2_floor <- .2 # note: check on this, but for purposes of indexing retention times in 2d this is important

# creating a column of the differences in linear retention indecies so that poor matches can be screened out
M_t_LRI <- M_t_full3 %>% mutate(LRI_diff = abs(Library.RI-LRI.I)) %>% 
  mutate(LRI_diff = replace_na(LRI_diff, -999))

btz2 <- M_t_LRI %>% 
  filter(Compound.Name == "20200803_1535_blob_958_")
# its here too

# getting rid of things that should be removed
remove_match <- M_t_LRI %>% 
  filter(Library.Name == lib_remove_1 | Library.Name == lib_remove_2 | Library.Name == lib_remove_3 | Library.Name == lib_remove_4)

btz3 <- remove_match %>% 
  filter(Compound.Name == "20200803_1535_blob_958_")
# not here, good

# identifying the internal standard
IS_goodmatch <- M_t_LRI %>% 
  filter(Library.Name == IS_lib_name | Library.Name == "-") %>% 
  filter(LRI_diff < LRI_diff_floor) %>% 
  filter(Library.Match.Factor > Match_factor_floor| Description== "match")  

# FB_goodmatch <- M_t_LRI %>% 
#   filter(Library.Name == FB_lib_name) %>% 
#   filter(LRI_diff < LRI_diff_floor) %>% 
#   filter(Library.Match.Factor > fb_match_factor_floor)
# 
# FB_okmatch <- M_t_LRI %>% 
#   filter(Library.Name == FB_lib_name) %>% 
#   filter(Library.Match.Factor> fb_match_factor_floor-100) %>% 
#   anti_join(FB_goodmatch)
  
IS_okmatch <- M_t_LRI %>% 
  filter(Library.Name == IS_lib_name | Library.Name == "-") %>%
  filter(Library.Match.Factor > Match_factor_floor-100)  %>% 
  anti_join(IS_goodmatch)

small_poorlymatched <- M_t_LRI %>% 
  filter(Library.Match.Factor < Match_factor_floor) %>% 
  filter(Volume < 200)

btz4 <- small_poorlymatched %>% 
  filter(Compound.Name == "20200803_1535_blob_958_")
# 33/70 in here, makes sense

M_t_all_analytes <- M_t_LRI %>% 
  #anti_join(FB_goodmatch) %>% 
  anti_join(IS_goodmatch) %>% 
  #anti_join(FB_okmatch) %>% 
  anti_join(IS_okmatch) %>% 
  anti_join(remove_match) %>% 
  anti_join(small_poorlymatched) %>% 
  filter(LRI.I > 1200) 

btz1 <- M_t_all_analytes %>% 
  filter(Compound.Name == "20200803_1535_blob_958_")

## Getting rid of things that existed and were well matched in the tap water blank



tap_water_blank <- read_csv("Read_Files/CAICE_tapwater_ssasearched.csv")

names(tap_water_blank) <- make.names(names(tap_water_blank),unique = TRUE) 

tap_water_blank_matches <- tap_water_blank %>% 
  filter(Library.Match.Factor > 750) %>% 
  filter(Library.Name != "caice_ssi") %>% 
  filter(Volume > 10000) %>% 
  dplyr::select(Compound.Name) %>% 
  mutate(in_background = 1)

M_t_all_analytes <- M_t_all_analytes %>% 
  left_join(tap_water_blank_matches) %>% 
  filter(is.na(in_background))

  
M_t_analyte_unique <- M_t_all_analytes %>% 
  arrange((r_date)) %>% 
  filter(Library.Name != IS_lib_name) %>% 
  filter(LRI_diff < LRI_diff_floor) %>% 
  filter(Library.Match.Factor > Match_factor_floor | Description == "match") %>% 
  #filter(Library.Reverse.Match.Factor > Reverse_match_factor_floor) %>% 
  arrange(desc(Volume)) %>% 
  arrange(Compound.Name) %>% 
  arrange(r_date) %>% 
  distinct(Compound.Name, r_date, .keep_all = TRUE) 




```
Important to note: the blob names are messed up for the template from 0805- still listed as from 0803


Tracing Library Performance
```{r}

# tracking the mass of all of the analytes before bad matches are screened out for later analysis of library performance
M_t_all_analytes_volcount <- M_t_all_analytes %>% 
  group_by(File_num) %>% 
  summarise(rawvol = sum(Volume))

# tracking the number of all analutes in
M_t_all_analytes_ncount <- M_t_all_analytes %>% 
  count(File_num) %>% 
  rename(total_num_analyte = n)

M_t_match_analytes_volcount <- M_t_analyte_unique %>% 
  group_by(File_num) %>% 
  summarise(rawvol_match = sum(Volume))

M_t_match_analytes_ncount <- M_t_analyte_unique %>% 
  count(File_num) %>% 
  rename(total_num_analyte_match = n)

M_t_analyte_summary <- M_t_all_analytes_volcount %>% 
  left_join(M_t_all_analytes_ncount) %>% 
  left_join(M_t_match_analytes_volcount) %>% 
  left_join(M_t_match_analytes_ncount) %>% 
  mutate(perct_nfound = (total_num_analyte_match/total_num_analyte)*100) %>% 
  mutate(perct_volfound = (rawvol_match/rawvol)*100)

compound_pop <- M_t_analyte_unique %>% 
  count(Compound.Name) %>% 
  rename(comp.n = n) %>% 
  mutate(pct_of_samp = (comp.n/max(comp.n)*100))

M_t_analyte_count <- M_t_all_analytes %>% 
  count(File_num) %>%
  rename(total_num_analyte = n)
# 
# # counting the number of unique analytes in each image
num_analyte_unique <- M_t_analyte_unique %>%
  count(File_num) %>%
  rename(unique.analyte = n)

# counting the number based percent of compounds being traced in all 
perct_comps_traced <- num_analyte_unique %>% 
   left_join(M_t_analyte_count) %>% 
   mutate(pct_found = unique.analyte/total_num_analyte)
# 

summary(perct_comps_traced$pct_found)


M_t_analyte_unique <- M_t_analyte_unique %>% left_join(num_analyte_unique)

compound_pop <- M_t_analyte_unique %>% 
  count(Compound.Name) %>% 
  rename(comp.n = n) %>% 
  mutate(pct_of_samp = (comp.n/max(comp.n)*100))

table(compound_pop$comp.n)

hist(compound_pop$pct_of_samp, 
     main = paste("Histogram of", nrow(compound_pop), "Traced Compounds\nOver Seascape Bloom 3"),
     xlab = "Percent Occurence Above Detection Limits",
     col = "grey")

SeaScape_sample_cumcum <- M_t_analyte_unique %>% 
  group_by(File_num) %>% 
  summarise(File_vol = sum(Volume))


M_t_analyte_unique <- M_t_analyte_unique %>% 
  left_join(compound_pop) %>% 
  left_join(SeaScape_sample_cumcum) %>% 
  mutate(Volume_Fraction = Volume/File_vol)


M_t_analyte_unique %>% 
  mutate(char_comp_n = as.integer(round(pct_of_samp, 0))) %>% 
  group_by(char_comp_n) %>% 
  summarise(avg_vol_byn = mean(Volume)) %>% 
  ggplot(aes(x = char_comp_n, y = avg_vol_byn)) +
  geom_col()+
  labs(title = "Average Blob Volume by Library Match Frequency")+
  xlab("Percent of Samples with Positive Library Match")+
  ylab("Average Blob Volume")

```

```{r fig.width=2, fig.height=3, warning = FALSE}


M_t_analyte_summary %>% 
  ggplot(aes(y = perct_nfound))+
  geom_boxplot(fill = "pink") + 
  theme_bw()+
  ylab("Percent of Analytes Assigned to \nLibrary Match")

M_t_analyte_summary %>% 
  ggplot(aes(y = perct_volfound))+
  geom_boxplot(fill = "pink") + 
  theme_bw()+
  ylab("Percent of Analyte Volume Assigned to \nLibrary Match")

summary(M_t_analyte_summary$perct_volfound)

#weighted average of distances
#leave one out cross validation

#kriging- from geography
#GAM to build 2d surface 
# try predict with GAM or loess surface, 
# link function for GAM
# could use a moving window 
```



Tracking appearance of new compounds
```{r}

unique_tracing <- M_t_analyte_unique %>% 
  arrange(r_date)

unique_tag <- 
  unique_tracing %>% 
  filter(File_num == bt_sum_bloom3$File_num[1]) %>% 
  mutate(is_unique_prior = NA) %>% 
  dplyr::select(Compound.Name, File_num, is_unique_prior)


for(i in 2:nrow(bt_sum_bloom3)){
  
  
  
  previous_file_i <- bt_sum_bloom3$File_num[i-1]
  file_i <- bt_sum_bloom3$File_num[i]
  
  prev_compounds <- unique_tracing %>% 
    filter(File_num == previous_file_i) %>% 
    mutate(is_unique_prior = FALSE) %>% 
    dplyr::select(Compound.Name, is_unique_prior)
  
  compounds_i <- unique_tracing %>% 
    filter(File_num== file_i)
  
  
  unique_tag_t <- compounds_i %>% 
    left_join(prev_compounds, by = "Compound.Name") %>% 
    dplyr::select(Compound.Name, File_num, is_unique_prior)
  
  unique_tag <- rbind(unique_tag, unique_tag_t)
    
  
}

unique_tracing_c <- unique_tracing %>% 
  left_join(unique_tag, by = c("Compound.Name", "File_num")) %>% 
  mutate(unique_log = is.na(is_unique_prior)) %>% 
  mutate(unique_vol = unique_log * Volume/(Punch_num_sample_time_norm)) 


avg_unique = sum(unique_tracing_c$unique_vol)/sum(unique_tracing_c$Volume)

```

more unique tracing

```{r}
unique_tracing_c %>% 
  #filter(IOP == 2) %>% 
  mutate(ones = 1) %>% 
  ggplot(aes(fill = unique_log, y = ones, x = r_date))+
  geom_bar(position = "stack", stat = "identity")+
  ylab("Analyte Count")




unique_tracing_c %>% 
  #filter(IOP == 2) %>% 
  mutate(ones = 1) %>% 
  ggplot(aes(fill = unique_log, y = Punch_t_norm_vol, x = r_date))+
  geom_bar(position = "stack", stat = "identity")+
  ylab("Analyte Raw Volume")+
  xlab("Dry Season GoAmazon Date")+
  scale_fill_manual(name = "Unique Compared\n to Previous Sample", values=c("blue", "green"))+
  theme(axis.text.x = element_text(size=14), axis.text.y = element_text(size=14), axis.text=element_text(size=12),
        axis.title=element_text(size=14))


  
  
```
Adding in cumsum and pct found to analyte unique for raw timelines
```{r pressure, importing chemical info}

compiled_comp_info <- read_csv("Read_Files/Compiled_Compoundinfo_Blobtable_SS.csv")

names(compiled_comp_info) <- make.names(names(compiled_comp_info),unique = TRUE)

compiled_comp_info.findable <- compiled_comp_info %>% 
  filter(Library.Match.Factor_NISTmain> 800) %>% 
  mutate(Identifiable = TRUE) %>% 
  dplyr::select(Compound.Name, Identifiable)

#id.tags <- data.frame("Identifiable"= c(TRUE, NA), ID)

compiled_comp_info <- compiled_comp_info %>% 
  left_join(compiled_comp_info.findable) %>% 
  mutate(tic = 1)

compiled_comp_info %>% 
  ggplot(aes(x = "", y = tic, fill = Identifiable)) + 
  geom_col()+
  coord_polar("y", start = 0)+
  theme_classic() +
  theme(plot.title = element_text(hjust=0.5),
        axis.line = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank()) +
  labs(fill = "",
       x = NULL,
       y = NULL) + 
  ggtitle("765 Novel and Identifiable\nSubmicron SSA Compounds- SeaScape")

```


```{r}
SeaScape_cumsum_raw <- M_t_analyte_unique %>% 
  mutate(tic = 1) %>% 
  group_by(Compound.Name) %>% 
  summarise(raw_cumsum = sum(Punch_t_norm_vol), num_obs = sum(tic)) %>% 
  mutate(pct_obs = num_obs/nrow(bt_sum_bloom3)) %>% 
  arrange(desc(raw_cumsum))





M_t_analyte_unique_info <- M_t_analyte_unique %>% 
  left_join(SeaScape_cumsum_raw, by = "Compound.Name") %>% 
  left_join(compiled_comp_info, by = "Compound.Name") %>% 
  left_join(compiled_comp_info.findable, by = "Compound.Name")

for(i in 1:nrow(compiled_comp_info.findable)){
  findable_c <- compiled_comp_info$Compound.Name[i]
  
  f1 <- M_t_analyte_unique_info %>% 
    filter(Compound.Name == findable_c) %>% 
    ggplot(aes(x = r_date, y = Punch_t_norm_vol, color = Compound.Name_NISTmain))+
    geom_line()
  
  print(f1)
  
  
  
  
}


# for(i in 1:100){
#   big_c <- SeaScape_cumsum_raw$Compound.Name[i]
#   
#   f2 <- M_t_analyte_unique_info %>% 
#     filter(Compound.Name == big_c) %>% 
#     ggplot(aes(x = r_date, y = Volume_Fraction, color = Compound.Name_NISTmain))+
#     geom_line()+
#     geom_point(aes(x = r_date, y = Volume_Fraction, shape = T_O_D, fill = Library.Match.Factor_NISTmain))
#   
#   print(f2)
#   
#   
#   
#   
# }

# for(i in 1:100){
#   big_c <- SeaScape_cumsum_raw$Compound.Name[i]
#   
#   f3 <- M_t_analyte_unique_info %>% 
#     filter(Compound.Name == big_c) %>% 
#     ggplot(aes(x = r_date, y = Punch_t_norm_vol, color = Compound.Name_NISTmain))+
#     geom_line()+
#     geom_point(aes(x = r_date, y = Punch_t_norm_vol, shape = T_O_D, fill = Library.Match.Factor_NISTmain))
#   
#   print(f3)
#   
#   
# }



```


Internal Standard Mapping

```{r IS_mapping1}
# note: unlike sample analytes, internal standard compounds are frequently split vertically into multiple blobs because of the high volume.  In order to account for this, I am summing all blobs together that meet the high match criteria and are very close in the first dimension.
IS_unique <- IS_goodmatch %>% 
  group_by(Compound.Name, File_num) %>% 
  summarise(Volume_tot = sum(Volume)) %>% 
  filter(Compound.Name != "glucose-13C6") %>% 
  filter(Compound.Name != "dC14") 

fixing <- data.frame(table(IS_unique$Compound.Name)) %>% 
  mutate(Compound.Name = Var1)

IS_tofix <- IS_unique %>% 
  left_join(fixing) %>% 
  filter(Freq < 37) %>% 
  left_join(bt_sum_bloom3, by = "File_num")

IS_unique_c <- IS_unique %>% 
  mutate(tic = 1) %>% 
  group_by(File_num) %>% 
  summarise(ticsum = sum(tic))

c<- data.frame(table(IS_unique$Compound.Name))

# note: this is not knitting, not sure why but did temporary work around
# IS_positions <- IS_goodmatch %>% 
#   filter(Compound.Name != "glucose-13C6") %>% 
#   filter(Compound.Name != "dC14") %>% 
#   group_by(Compound.Name, File_num) %>% 
#   #summarise(LRI_avg = mean(LRI.I), RI2 = min(Retention.II..sec.-rt2_floor))
#   summarise(LRI_avg = mean(LRI.I), RI2 = min(Retention.II..sec. - rt2_floor))
# 
# IS_positions_knit <- write.csv(IS_positions, "IS.pos.knit.csv2")

IS_positions <- read.csv("Read_Files/IS.pos.knit.csv") %>% 
  dplyr::select(-X)
  

IS_avg_vols_toadd <- IS_unique %>% 
  group_by(Compound.Name) %>% 
  summarise(IS_avgvol = mean(Volume_tot), IS_medvol = median(Volume_tot)) %>% 
  left_join(IS_unique) %>% 
  mutate(IS_mean_norm = Volume_tot / IS_avgvol) %>%
  mutate(IS_med_norm = Volume_tot / IS_medvol) %>% 
  dplyr::select(Compound.Name, File_num, IS_mean_norm)

IS_unique_pos <- IS_unique %>% 
  left_join(IS_positions) %>% 
  left_join(IS_avg_vols_toadd)



IS_test1 <- IS_unique_pos %>% 
  filter(File_num == "GCxGC_20200803_1001")

IS_1_vol <- IS_test1$Volume_tot
RI1 <- IS_test1$LRI_avg
RI2 <- IS_test1$RI2

# IS_1_pos <- IS_test1 %>% 
#   ungroup() %>% 
#   dplyr::select("LRI_avg", "RI2")
IS_positions_202008061332 <- read.csv("Read_Files/GCxGC_20200806_1332.h5_img01_IS_selected_positions_Blob_Table.csv")
IS_rt2 <- IS_positions_202008061332 %>% 
  dplyr::select(Compound.Name, Retention.II..sec.)

IS_positions <- IS_goodmatch %>% 
  filter(Compound.Name != "glucose-13C6") %>% 
  filter(Compound.Name != "dC14") %>% 
  group_by(Compound.Name, File_num) %>% 
  #summarise(LRI_avg = mean(LRI.I), RI2 = min(Retention.II..sec.-rt2_floor))
  summarise(LRI_avg = mean(LRI.I), RI2 = min(Retention.II..sec. - rt2_floor))


IS_positions_avg <- IS_positions %>% 
  group_by(Compound.Name) %>% 
  summarise(LRI_avg_all = mean(LRI_avg, na.rm = TRUE), Retention.II..sec. = mean(RI2, na.rm = TRUE)) 


write.csv(IS_positions_avg, "Write_Files/IS_positions_avg.csv")


IS_avg_vols <- IS_unique %>% 
  group_by(Compound.Name) %>% 
  summarise(IS_avgvol = mean(Volume_tot), IS_medvol = median(Volume_tot)) %>% 
  left_join(IS_unique) %>% 
  mutate(IS_mean_norm = Volume_tot / IS_avgvol) %>%
  mutate(IS_med_norm = Volume_tot / IS_medvol) %>% 
  left_join(bt_sum_bloom3)

IS_cat <- read.csv("Read_Files/IS_withcat.csv")
IS_cat <- IS_cat %>% 
  dplyr::select(-X)

IS_avg_vols <- IS_avg_vols %>% 
  left_join(IS_cat)
  

IS_just_one_IS <- IS_avg_vols %>% 
  filter(Compound.Name == "dC24") %>% 
  dplyr::select(File_num, dalk_norm=IS_mean_norm) 

IS_stability <- IS_avg_vols %>% 
  left_join(IS_just_one_IS) %>% 
  left_join(IS_positions_avg)

IS_stability %>% 
  ggplot(aes(x = dalk_norm, y = IS_mean_norm, color = F_group_cat))+
  geom_point()+
  ylim(0, 2) +
  xlim(0,2)
  



IS_avg_vols %>% ggplot(aes(x = r_date, y = IS_med_norm, color = Compound.Name)) +
  geom_point()
  

IS_avg_vols %>% ggplot(aes(x = r_date, y = Volume_tot, color = Compound.Name)) +
  geom_point()

IS_stability %>% 
  ggplot(aes(x = LRI_avg_all, y = IS_mean_norm, color = r_date))+
  geom_point()

IS_stability %>% 
  ggplot(aes(x = LRI_avg_all, y = Volume_tot, color = r_date))+
  geom_point()

IS_stability %>% 
  ggplot(aes(x = Retention.II..sec., y = IS_mean_norm, color = r_date))+
  geom_point()

IS_stability %>% 
  ggplot(aes(x = Retention.II..sec., y = Volume_tot, color = r_date))+
  geom_point()

IS_stability %>% 
  ggplot(aes(x = LRI_avg_all, y = IS_mean_norm, color = F_group_cat))+
  geom_point()

IS_stability %>% 
  ggplot(aes(x = LRI_avg_all, y = Volume_tot, color = F_group_cat))+
  geom_point()

IS_stability %>% 
  ggplot(aes(x = Retention.II..sec., y = IS_mean_norm, color = F_group_cat))+
  geom_point()

IS_stability %>% 
  ggplot(aes(x = Retention.II..sec., y = Volume_tot, color = F_group_cat))+
  geom_point()
```
Conclusion: Normalizing by the nearest mean or median normalized internal standard volume is most appropriate, as the responses of different internal standard on a raw volume basis are a function of chemical characteristics rather than purely instrument response (itself a function of matrix effects and instrument condition, which cannot be effectively deconvoluted).  As the quantification model takes into account chemical characteristics through a machine learning model trained on the mass spectrum, normalization by raw internal standard volume introduces covarying factors.

```{r IS_mapping2}
LRI_weight = 10
LRII_weight = 1

LRI1_avg = mean(IS_positions_avg$LRI_avg_all, na.rm = TRUE)
LRI2_avg = mean(IS_positions_avg$Retention.II..sec.)

IS_positions_avg <- IS_positions_avg %>% 
  mutate(relative_LRI = (LRI_avg_all/LRI1_avg)*LRI_weight) %>% 
  mutate(relative_LRI2 = (Retention.II..sec./LRI2_avg)*LRII_weight)

write.csv(IS_positions_avg, "Write_Files/IS_positions_avg_rel.csv")

Analyte_positions_trial <- M_t_analyte_unique %>% 
  group_by(Compound.Name, File_num) %>% 
  summarise(LRI_avg = mean(LRI.I), RI2 = min(Retention.II..sec. - rt2_floor))

# note filtering out three small blobs outside of RI window

Analyte_positions <- M_t_analyte_unique %>% 
  filter(!is.na(LRI.I)) %>% 
  group_by(Compound.Name) %>% 
  summarise(LRI_avg = mean(LRI.I, na.rm = TRUE), RI2 = (mean(Retention.II..sec.) - rt2_floor))

Analyte_positions <- Analyte_positions %>% 
  mutate(relative_LRI = (LRI_avg/LRI1_avg)*LRI_weight) %>% 
  mutate(relative_LRI2 = (RI2/LRI2_avg)*LRII_weight)

# checking to make sure that the ranges match up, eg back end checking that same norm method used on moth IS and analyte positions
summary(IS_positions_avg$relative_LRI)
summary(Analyte_positions$relative_LRI)
summary(IS_positions_avg$relative_LRI2)
summary(Analyte_positions$relative_LRI2)

Analyte_pos_short <- Analyte_positions %>% 
  dplyr::select(relative_LRI, relative_LRI2)

IS_pos_short <- IS_positions_avg %>% 
  dplyr::select(relative_LRI, relative_LRI2)

#knn(IS_pos_short, Analyte_pos_short, cl=IS_pos_short$Compound.Name, k=1, l=0)

#Old method, only using 1 nearest
#testnn <- nn2(IS_pos_short, query = Analyte_pos_short, treetype = "kd", searchtype = "standard", k=1)

# note 1.19 is the min radius at which every compound has at least one nearest
testnn <- nn2(IS_pos_short, query = Analyte_pos_short, treetype = "kd", searchtype = "radius", k=3, radius = 3.9)


Analyte_IS_Index <- data.frame(testnn$nn.idx)
# old method only using 1 nearest
# Analyte_pos_ad <- data.frame(Compound.Name = Analyte_positions$Compound.Name, IS_index = Analyte_IS_Index)

Analyte_pos_ad <- data.frame(Compound.Name = Analyte_positions$Compound.Name, IS_index1 = Analyte_IS_Index$X1, IS_index2 = Analyte_IS_Index$X2, IS_index3 = Analyte_IS_Index$X3)

# old method with only 1 IS
# Analyte_with_IS <- Analyte_pos_ad %>% 
#   mutate(IS_appropriate = IS_positions_avg$Compound.Name[IS_index])

# Analyte_with_IS <- Analyte_pos_ad %>% 
#   mutate(IS_appropriate1 = IS_positions_avg$Compound.Name[IS_index1]) %>% 
#   mutate(IS_appropriate2 = IS_positions_avg$Compound.Name[IS_index2]) %>% 
#   mutate(IS_appropriate3 = IS_positions_avg$Compound.Name[IS_index3])

Analyte_with_IS <- Analyte_pos_ad %>% 
  mutate(IS_appropriate1 = NA) %>% 
  mutate(IS_appropriate2 = NA) %>% 
  mutate(IS_appropriate3 = NA)

for(i in 1:nrow(Analyte_with_IS)){
  t_isind_1 <- Analyte_with_IS$IS_index1[i]
  t_isind_2 <- Analyte_with_IS$IS_index2[i]
  t_isind_3 <- Analyte_with_IS$IS_index3[i]
  
  if(t_isind_1 > 0){
  t_isap_1 <- IS_positions_avg$Compound.Name[t_isind_1]
  }else{
    t_isap_1 <- NA
  }
  
  if(t_isind_2 > 0){
  t_isap_2 <- IS_positions_avg$Compound.Name[t_isind_2]
  }else{
    t_isap_2 <- NA
  }
  
  if(t_isind_3 > 0){
  t_isap_3 <- IS_positions_avg$Compound.Name[t_isind_3]
  }else{
    t_isap_3 <- NA
  }
  
  
  
  Analyte_with_IS$IS_appropriate1[i] <- t_isap_1
  Analyte_with_IS$IS_appropriate2[i] <- t_isap_2
  Analyte_with_IS$IS_appropriate3[i] <- t_isap_3
  
}

# Analyte_with_IS_positions <- Analyte_with_IS %>% 
#   left_join(Analyte_positions) %>% 
#   left_join(IS_positions_avg, by = c("IS_appropriate"= "Compound.Name"))

Analyte_with_IS_positions <- Analyte_with_IS %>% 
  left_join(Analyte_positions) %>% 
  left_join(IS_positions_avg, by = c("IS_appropriate1"= "Compound.Name")) %>% 
  left_join(IS_positions_avg, by = c("IS_appropriate2"= "Compound.Name")) %>% 
  left_join(IS_positions_avg, by = c("IS_appropriate3"= "Compound.Name"))

M_t_analyte_withIS <- M_t_analyte_unique %>% 
  left_join(Analyte_with_IS) %>% 
  mutate(IS_vol1= -999*(LRI.I/LRI.I)) %>% 
  mutate(IS_mean_norm1= -999*(LRI.I/LRI.I)) %>% 
  mutate(IS_vol2= -999*(LRI.I/LRI.I)) %>% 
  mutate(IS_mean_norm2= -999*(LRI.I/LRI.I)) %>% 
  mutate(IS_vol3= -999*(LRI.I/LRI.I)) %>% 
  mutate(IS_mean_norm3= -999*(LRI.I/LRI.I)) %>% 
  mutate(IS_vol_dalk= -999*(LRI.I/LRI.I)) %>% 
  mutate(IS_mean_norm_dalk= -999*(LRI.I/LRI.I))

# old- only 1 IS
# M_t_analyte_withIS <- M_t_analyte_unique %>% 
#   left_join(Analyte_with_IS) %>% 
#   mutate(IS_vol= -999*(LRI.I/LRI.I)) %>% 
#   mutate(IS_mean_norm= -999*(LRI.I/LRI.I)) 


# for(i in 1:nrow(M_t_analyte_withIS)){
#   
#   
#   IS_name = M_t_analyte_withIS$IS_appropriate[i]
#   File_num_t = M_t_analyte_withIS$File_num[i]
#   
#   IS_indicated <- IS_stability %>% 
#     filter(Compound.Name == IS_name) %>% 
#     filter(File_num == File_num_t)
#   
#   M_t_analyte_withIS$IS_vol[i] <-IS_indicated$Volume_tot[1]
#   M_t_analyte_withIS$IS_mean_norm[i] <-IS_indicated$IS_mean_norm[1]
#   
#   
# }

for(i in 1:nrow(M_t_analyte_withIS)){
  
  
  
  IS_name1 = M_t_analyte_withIS$IS_appropriate1[i]
  IS_name2 = M_t_analyte_withIS$IS_appropriate2[i]
  IS_name3 = M_t_analyte_withIS$IS_appropriate3[i]
  
  
  
  
  File_num_t = M_t_analyte_withIS$File_num[i]
  
  IS_indicated1 <- IS_stability %>% 
    filter(Compound.Name == IS_name1) %>% 
    filter(File_num == File_num_t)
  
  M_t_analyte_withIS$IS_vol1[i] <-IS_indicated1$Volume_tot[1]
  M_t_analyte_withIS$IS_mean_norm1[i] <-IS_indicated1$IS_mean_norm[1]
  
  IS_indicated2 <- IS_stability %>% 
    filter(Compound.Name == IS_name2) %>% 
    filter(File_num == File_num_t)
  
  M_t_analyte_withIS$IS_vol2[i] <-IS_indicated2$Volume_tot[1]
  M_t_analyte_withIS$IS_mean_norm2[i] <-IS_indicated2$IS_mean_norm[1]
  
  IS_indicated3 <- IS_stability %>% 
    filter(Compound.Name == IS_name3) %>% 
    filter(File_num == File_num_t)
  
  M_t_analyte_withIS$IS_vol3[i] <-IS_indicated3$Volume_tot[1]
  M_t_analyte_withIS$IS_mean_norm3[i] <-IS_indicated3$IS_mean_norm[1]
  
}

# 
# M_t_analyte_withIS <- M_t_analyte_withIS %>% 
#   mutate(vol_is_normnorm = Volume/IS_mean_norm) %>% 
#   mutate(vol_is_rawnorm = Volume/IS_vol)
#   

# note- this step is not working
# M_t_analyte_withIS <- M_t_analyte_withIS %>% 
#   mutate(IS_vol = mean(c(IS_vol1, IS_vol2, IS_vol3), na.rm = TRUE)) %>% 
#   mutate(IS_mean_norm = mean(c(IS_mean_norm1, IS_mean_norm2, IS_mean_norm3), na.rm = TRUE))

for(i in 1:nrow(M_t_analyte_withIS)){
  
  isvols_raw <- c(M_t_analyte_withIS$IS_vol1[i], M_t_analyte_withIS$IS_vol2[i], M_t_analyte_withIS$IS_vol3[i])
  
  M_t_analyte_withIS$IS_vol[i] = mean(isvols_raw, na.rm = TRUE)
  
  isvols_norm <- c(M_t_analyte_withIS$IS_mean_norm1[i], M_t_analyte_withIS$IS_mean_norm2[i], M_t_analyte_withIS$IS_mean_norm3[i])
  
  M_t_analyte_withIS$IS_mean_norm[i] = mean(isvols_norm, na.rm = TRUE)
  
}


M_t_analyte_withIS <- M_t_analyte_withIS %>% 
  mutate(vol_is_normnorm = Volume/IS_mean_norm) %>% 
  mutate(vol_is_rawnorm = Volume/IS_vol) %>%
  mutate(vol_is_normnorm_ptnorm = vol_is_normnorm/(Punch_num_sample_time_norm)) %>% 
  mutate(vol_is_rawnorm_ptnorm = vol_is_rawnorm/(Punch_num_sample_time_norm))


IS_problems <- M_t_analyte_withIS %>% 
  filter(is.na(IS_appropriate1))

File_norm_totorg <- M_t_analyte_withIS %>% 
  group_by(r_date) %>% 
  summarise(vol_normnorm_total = sum(vol_is_normnorm_ptnorm), vol_rawnorm_total = sum(vol_is_rawnorm_ptnorm))

File_norm_totorg %>% 
  ggplot(aes(x = r_date, y = vol_rawnorm_total))+
  geom_point()

File_norm_totorg %>% 
  ggplot(aes(x = r_date, y = vol_normnorm_total))+
  geom_point()

M_t_analyte_withIS <- M_t_analyte_withIS %>% 
  left_join(File_norm_totorg) %>% 
  mutate(vol_is_normnorm_ptnorm_totorgnorm = vol_is_normnorm_ptnorm/vol_normnorm_total)


```

# adding in quant factors, some modeled some real
```{r}
QF_o <- read_csv("Read_Files/Compiled_Compound_info_SeaScape.quant_EBF_3.csv")
tot_org_o <- read_csv("Read_Files/Davis_Total_org.csv") %>% 
  mutate(r_date = mdy_hm(Date))

QF_s <- QF_o %>% 
  dplyr::select(Compound.Name, Quant_Factor_final)

# note just picking 1.4 as the organic mass to organic carbon ratio, check with Allen
OM_OC <- 1.4

# note that the siloxane peaks are being removed, because they likely were not quantified accurately
M_t_analyte_withIS.q <- M_t_analyte_withIS %>% 
  filter(Compound.Name != "20200803_1535_blob_3_fb") %>% 
  filter(Compound.Name != "20200803_1535_blob_19_") %>% 
  filter(Compound.Name != "20200803_1535_blob_453_") %>% 
  left_join(QF_s) %>% 
  dplyr::mutate(amt_ng = vol_is_normnorm * Quant_Factor_final) %>% 
  dplyr::mutate(amt_ng_per_cm3 = amt_ng/(.41*Filter_punches)) %>% 
  dplyr::mutate(amt_ng_ptnorm = amt_ng/Punch_num_sample_time_norm)

#write.csv(M_t_analyte_withIS.q, "quant_inspect.csv")

quant.prob <- M_t_analyte_withIS.q %>% 
  filter(is.na(amt_ng))

table(quant.prob$Compound.Name)
# check out these compounds to see why we dont have quant factors for them

#Now checking to see how our quantification compares to Davis

quant_sum_sample <- M_t_analyte_withIS.q %>% 
  group_by(r_date) %>% 
  summarise(tot_org_ng_cm3 = sum(amt_ng_per_cm3, na.rm = TRUE), 
            tot_org_ng_ptnorm = sum(amt_ng_ptnorm)) %>% 
  left_join(tot_org_o) %>% 
  mutate(OM_FB_corrected = OC_FB_corrected * OM_OC) %>% 
  mutate(frac_fb_rem = (.001*tot_org_ng_cm3)/ OM_FB_corrected)

quant_sum_sample %>% 
  ggplot(aes(x = r_date, y = .001*tot_org_ng_cm3, color = "GCxGC Measured"))+
  geom_point()+
  geom_point(aes(x = r_date, y = OM_FB_corrected, color = "Davis Total Organic Mass"))

quant_sum_sample %>% 
  ggplot(aes(x = r_date, y = .001*tot_org_ng_cm3, color = "GCxGC Measured"))+
  geom_point()+
  ylim(0, .7)

quant_sum_sample %>% 
  ggplot(aes(x = r_date, y = frac_fb_rem))+
  geom_point()

summary(quant_sum_sample$frac_fb_rem)

```


Adding fields to cumsum to reflect total org norm and IS normnorm so that factors can be weighted to equally emphasize things important at beginning and end of bloom
```{r}

SeaScape_normalized_cumsum <- M_t_analyte_withIS.q %>% 
  filter(!is.na(amt_ng_ptnorm)) %>% # adding this so that we are only tracking things that are quantified- revisit the missing quants later
  group_by(Compound.Name) %>% 
  summarise(totorgnorm_cumsum = sum(vol_is_normnorm_ptnorm_totorgnorm), isnormnormptnorm_cumsum = sum(vol_is_normnorm_ptnorm), quantcumsum = sum(amt_ng_ptnorm))

tot_norm_vol = sum(SeaScape_normalized_cumsum$isnormnormptnorm_cumsum, na.rm = TRUE)

SeaScape_normalized_cumsum_cumulative <- SeaScape_normalized_cumsum %>% 
  mutate(isnormnormptnorm_pct = isnormnormptnorm_cumsum/tot_norm_vol) %>% 
  mutate(isnormnorm_ptnorm_pct_cumulative = isnormnormptnorm_pct) %>% 
  arrange(desc(isnormnormptnorm_pct)) %>% 
  mutate(rownum = row_number())

for(i in 2:nrow(SeaScape_normalized_cumsum_cumulative)){
  SeaScape_normalized_cumsum_cumulative$isnormnorm_ptnorm_pct_cumulative[i]= SeaScape_normalized_cumsum_cumulative$isnormnormptnorm_pct[i]+ SeaScape_normalized_cumsum_cumulative$isnormnorm_ptnorm_pct_cumulative[i-1]
  
}

tot_org_norm <- sum(SeaScape_normalized_cumsum$quantcumsum)

SeaScape_normalized_cumsum.q <- SeaScape_normalized_cumsum %>% 
  mutate(quant_pct = quantcumsum/tot_org_norm) %>% 
  mutate(quant_pct_cumulative = quant_pct) %>% 
  arrange(desc(quant_pct)) %>% 
  mutate(rownum = row_number())

for(i in 2:nrow(SeaScape_normalized_cumsum.q)){
  SeaScape_normalized_cumsum.q$quant_pct_cumulative[i]= 
    SeaScape_normalized_cumsum.q$quant_pct[i]+ SeaScape_normalized_cumsum.q$quant_pct_cumulative[i-1]
  
}

SeaScape_normalized_cumsum.q %>% 
  ggplot(aes(x = log(rownum), y = quant_pct_cumulative))+
  geom_point()

```


# plotting normalized timelines, normalized by both total organic (red) and internal standard (blue) to get a general sense for underlying trends

```{r}

for(i in 1:50){
  
  print(i)
  big_c <- SeaScape_cumsum_raw$Compound.Name[i]
  
  f4 <- M_t_analyte_withIS %>% 
    filter(Compound.Name == big_c) %>% 
    left_join(compiled_comp_info, by = "Compound.Name") %>% 
    ggplot(aes(x = r_date, y = vol_is_normnorm_ptnorm_totorgnorm, color = Compound.Name))+
    geom_line()+
    geom_point(aes(x = r_date, y = vol_is_normnorm_ptnorm_totorgnorm, shape = T_O_D, fill = Library.Match.Factor_NISTmain))
  
  print(f4)
  
  f5 <- M_t_analyte_withIS %>% 
    filter(Compound.Name == big_c) %>% 
    left_join(compiled_comp_info, by = "Compound.Name") %>% 
    ggplot(aes(x = r_date, y = vol_is_normnorm_ptnorm, color = Compound.Name))+
    geom_line(color = "blue")+
    geom_point(aes(x = r_date, y = vol_is_normnorm_ptnorm, shape = T_O_D, fill = Library.Match.Factor_NISTmain))
  
  print(f5)
  
  
}

```
Plotting Quantified Timelines

```{r}
for(i in 1:50){
  temp_comp <- SeaScape_normalized_cumsum.q$Compound.Name[i]
  
  qf1 <- M_t_analyte_withIS.q %>% 
    filter(Compound.Name == temp_comp) %>% 
    left_join(compiled_comp_info, by = "Compound.Name") %>% 
    ggplot(aes(x = r_date, y = amt_ng_ptnorm, color = Compound.Name))+
    geom_line()+
    geom_point(aes(x = r_date, y = amt_ng_ptnorm, shape = T_O_D, fill = Library.Match.Factor_NISTmain))
  
  print(qf1)
  
}


```
```{r}
M_t_analyte_withIS.q.0 <- M_t_analyte_withIS.q %>% 
  dplyr::select(Compound.Name, r_date, amt_ng_ptnorm) %>%
  spread(Compound.Name,amt_ng_ptnorm, fill = 0) %>% 
  gather(key = "Compound.Name", value = "amt_ng_ptnorm", -r_date)
```


## Now trying with smoothed long data frame

```{r}
pct_floor = 20 # must be present in at least 20% of samples 
bt_lab <- bt_sum_bloom3 %>% 
  dplyr::select(r_date, Filter_num)

M_t_analyte_withIS_smoothed <- M_t_analyte_withIS.q %>% 
  filter(pct_of_samp > pct_floor) %>% 
  dplyr::select(Compound.Name, r_date, amt_ng_ptnorm) %>%
  spread(Compound.Name,amt_ng_ptnorm, fill = 0) %>% 
  gather(key = "Compound.Name", value = "amt_ng_ptnorm", -r_date) %>% 
  arrange(r_date) %>% 
  arrange(Compound.Name) %>% 
  mutate(amt_ng_ptnorm_smooth = amt_ng_ptnorm) %>% 
  left_join(bt_lab)

for(i in 2:nrow(M_t_analyte_withIS_smoothed)){

  a = i-1
  b = i
  c = i+1
  n1 <- M_t_analyte_withIS_smoothed$amt_ng_ptnorm[a]
 n2 <- M_t_analyte_withIS_smoothed$amt_ng_ptnorm[b]
 n3 <- M_t_analyte_withIS_smoothed$amt_ng_ptnorm[c]
 
 
  
  if(M_t_analyte_withIS_smoothed$Filter_num[i] == "UCB19_A_153"){
    M_t_analyte_withIS_smoothed$amt_ng_ptnorm_smooth[i]= n2
  }else if(M_t_analyte_withIS_smoothed$Filter_num[i] == "UCB19_A_197"){
    M_t_analyte_withIS_smoothed$amt_ng_ptnorm_smooth[i]= n2
  }else{
    nn <- (n1+n2+n3)/3
    M_t_analyte_withIS_smoothed$amt_ng_ptnorm_smooth[i]<- nn
    
  }
    
    
}
  
tt <- M_t_analyte_withIS_smoothed[21867,]


```



# Trying hierarchical clustering because DFA not working well

```{r}
library(tidyr)
library(dtwclust)
library(dplyr)
library(ggplot2)
#install.packages("reshape")
library(reshape)
```

```{r}

n_obs <- 100 # number of observations to keep for the factorization. 100 compounds is ~90% of the mass, so going with this. 
#n_factors <- 5

cumsum_keep <- SeaScape_normalized_cumsum.q[1:n_obs,]

cumsum_keep <- cumsum_keep %>% 
  mutate(keep = 1) %>% 
  dplyr::select(Compound.Name, keep)



df_long <- M_t_analyte_withIS_smoothed %>% 
  left_join(cumsum_keep) %>% 
  filter(keep == 1) %>% 
  dplyr::select(Compound.Name, r_date, amt_ng_ptnorm_smooth)



df_list <- as.list(utils::unstack(df_long, amt_ng_ptnorm_smooth ~ Compound.Name))

df_list_z <- dtwclust::zscore(df_list)

set.seed(20)
cluster_dtw_h <-list()
for (i in 2:20)
{
  cluster_dtw_h[[i]] <- tsclust(df_list_z, type = "h", k = i,  distance = "dtw", control = hierarchical_control(method = "complete"), seed = 590, preproc = NULL, args = tsclust_args(dist = list(window.size = 5L)))
}

# take a look at the object
cluster_dtw_h[[8]]

plot(cluster_dtw_h[[8]], type = "sc")
plot(cluster_dtw_h[[7]], type = "sc")
plot(cluster_dtw_h[[6]], type = "sc")
plot(cluster_dtw_h[[5]], type = "sc")
plot(cluster_dtw_h[[4]], type = "sc")
plot(cluster_dtw_h[[3]], type = "sc")


1
cvi(cluster_dtw_h[[5]], type = "valid")
cvi(cluster_dtw_h[[6]], type = "valid")
cvi(cluster_dtw_h[[7]], type = "valid")
cvi(cluster_dtw_h[[8]], type = "valid")
cvi(cluster_dtw_h[[9]], type = "valid")

# from this appears that 8 clusters is ideal, based on maximizing Sil
```


```{r}
fit <- cluster_dtw_h[[8]]
clustered_data <- cutree(fit, k=8)
clustered_data_tidy <- as.data.frame(as.table(clustered_data)) %>% glimpse()
colnames(clustered_data_tidy) <- c("Compound.Name","cluster")
clustered_data_tidy$Compound.Name <- as.character(clustered_data_tidy$Compound.Name)
glimpse(clustered_data_tidy)
table(clustered_data_tidy$cluster)

clustered_data_tidy <- clustered_data_tidy %>% 
  mutate(Compound.Name = sub('.', '', Compound.Name))


```

```{r}
smoothed_zscoreparams <- M_t_analyte_withIS_smoothed %>% 
  group_by(Compound.Name) %>% 
  summarise(c.mean = mean(amt_ng_ptnorm_smooth), c.stdev = sd(amt_ng_ptnorm_smooth))

M_t_analyte_withIS_smoothed.zscore <- M_t_analyte_withIS_smoothed %>% 
  left_join(smoothed_zscoreparams) %>% 
  mutate(amt_ng_ptnorm_smooth.zscore = (amt_ng_ptnorm_smooth-c.mean)/c.stdev)



```


```{r}
cluster_1 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 1) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_1 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 1")

cluster_2 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 2) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_2 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 2")

cluster_3 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 3) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_3 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 3")

cluster_4 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 4) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_4 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 4")

cluster_5 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 5) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_5 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 5")

cluster_6 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 6) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_6 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 6")

cluster_7 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 7) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_7 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 7")

cluster_8 <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(cluster == 8) %>% 
  group_by(r_date) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_8 %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z))+
  geom_line()+
  ggtitle("Cluster 8")

cluster_all <- M_t_analyte_withIS_smoothed.zscore %>%
  left_join(clustered_data_tidy) %>% 
  filter(!is.na(cluster)) %>% 
  group_by(r_date, cluster) %>% 
  summarise(cluster_vol.z = mean(amt_ng_ptnorm_smooth.zscore))

cluster_all %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z, color = as.factor(cluster)))+
  geom_line()
```


```{r}
h.clust.factors.z <- data.frame(cluster = c(1,2,3,4,5,6,7,8,9), cluster_factors = c("Factor A", "Factor B", "Factor C", "Factor D", "Factor E", "Factor F", "Factor G", "Factor H", "Factor I"), cluster_factor_types = c("Biogenic1", "Anthro1", "Mixed4", "Mixed2", "Mixed1", "Anthro2", "Mixed3", "Mixed5", "R-Btz"))

cluster_all %>% 
  left_join(h.clust.factors.z) %>% 
  ggplot(aes(x = r_date, y = cluster_vol.z, color = as.factor(cluster_factors)), size = 1.2)+
  geom_line()+
  geom_point(data = bt_sum_bloom3, aes(x = r_date, y = Extracted_Chla/10), color = "green1", size = 2)+
  geom_point(data = bt_sum_bloom3, aes(x = r_date, y = Bulk_HB/3000000), color = "red1", size = 2)




smooth_zscore_forcorr <- M_t_analyte_withIS_smoothed.zscore %>% 
  dplyr::select(r_date, Compound.Name, amt_ng_ptnorm_smooth.zscore) %>% 
  spread(Compound.Name, amt_ng_ptnorm_smooth.zscore) %>% 
  dplyr::select(-r_date)

smooth_zscore_forcorr$F1 <- cluster_1$cluster_vol.z
smooth_zscore_forcorr$F2 <- cluster_2$cluster_vol.z
smooth_zscore_forcorr$F3 <- cluster_3$cluster_vol.z
smooth_zscore_forcorr$F4 <- cluster_4$cluster_vol.z
smooth_zscore_forcorr$F5 <- cluster_5$cluster_vol.z
smooth_zscore_forcorr$F6 <- cluster_6$cluster_vol.z
smooth_zscore_forcorr$F7 <- cluster_7$cluster_vol.z
smooth_zscore_forcorr$F8 <- cluster_8$cluster_vol.z





hclust_smooth_zscore_corr <- data.frame(cor(smooth_zscore_forcorr), use = "pairwise.complete.obs")

just_cluster_corr <-  hclust_smooth_zscore_corr %>% 
  dplyr::select(F1, F2, F3, F4, F5, F6, F7, F8) 


assignments <- colnames(just_cluster_corr)[max.col(just_cluster_corr, ties.method = "first")]



just_cluster_corr$best_corr <- assignments

cluster_corr_hclust <- just_cluster_corr %>% 
  rownames_to_column(var = "Compound.Name") %>% 
  filter(Compound.Name != "F1") %>% 
  filter(Compound.Name != "F2") %>%
  filter(Compound.Name != "F3") %>% 
  filter(Compound.Name != "F4") %>% 
  filter(Compound.Name != "F5") %>% 
  filter(Compound.Name != "F6") %>% 
  filter(Compound.Name != "F7") %>% 
  filter(Compound.Name != "F8") %>% 
  left_join(clustered_data_tidy)

table(cluster_corr_hclust$best_corr)

cluster_corr_infor <- cluster_corr_hclust %>% 
  left_join(compiled_comp_info)

#write.csv(cluster_corr_infor, "cluster_correlation_info_inspect.csv")

cluster_assignments <- read_csv("Read_Files/Cluster_Assignments_Manual_Check_SeaScape.csv") %>% 
  dplyr::select(Compound.Name, cluster_assigned)

```

```{r}
bio_markers1 <- bt_sum_bloom3 %>% 
  dplyr::select(Event_label, r_date, Event_lab_order) %>% 
  filter(!is.na(Event_label)) %>% 
  mutate(biomarker_mag= 4)

bio_markers2 <- bt_sum_bloom3 %>% 
  dplyr::select(Event_label, r_date, Event_lab_order) %>% 
  filter(!is.na(Event_label)) %>% 
  mutate(biomarker_mag= -2)

bio_markers <- rbind(bio_markers1, bio_markers2)
```


```{r}
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

n = 8
cols = gg_color_hue(n)

dev.new(width = 4, height = 4)
plot(1:n, pch = 16, cex = 2, col = cols)
```

```{r}
maxh <- max(cluster_all$cluster_vol.z)
minh <- min(cluster_all$cluster_vol.z)


hclust_anthro <- cluster_all %>% 
  left_join(h.clust.factors.z) %>% 
  filter(cluster_factors == "Factor B" | cluster_factors == "Factor F")

pan<- ggplot()+
  geom_col(data = bio_markers, aes(x = r_date, y = biomarker_mag, fill = Event_label), width = 20000)+
  geom_line(data = hclust_anthro, aes(x = r_date, y = cluster_vol.z, color = cluster_factors), size = 1.2)+
  theme_bw()+
  ylab("Mean Cluster Abundance\n(Z-Scored)")+
  ggtitle("Anthropogenic Influence Clusters")+
  theme(plot.title = element_text(size = 18, hjust = 0.5),legend.text = element_text(size = 16), legend.title = element_blank(), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), axis.title.y = element_text(size = 18))+
  #ylim(minh, maxh)+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))+
  xlab("")+
  #guides(fill=guide_legend(nrow=2,byrow=TRUE))+
  scale_color_manual(values = cols[1:2], labels = c("Anthropogenic A", "Anthropogenic B"))+
  scale_fill_manual(values = c("darkgreen", "blue4"), labels = c( "Peak Chlorophyll", "Peak Bacteria"))+
  guides(fill = guide_legend(order = 1),color = guide_legend(order = 2))

pan

png("anthro_clusters2.png", width=8, height=5,
    units="in", res=600, pointsize=12)
pan
dev.off()



hclust_mix <- cluster_all %>% 
  left_join(h.clust.factors.z) %>% 
  filter(cluster_factors == "Factor C" | cluster_factors == "Factor D"| 
           cluster_factors == "Factor E"|
           cluster_factors == "Factor G" | cluster_factors == "Factor H"|
           cluster_factors == "Factor I")

pmix<- ggplot()+
  geom_col(data = bio_markers, aes(x = r_date, y = biomarker_mag, fill = Event_label), width = 20000)+
  geom_line(data = hclust_mix, aes(x = r_date, y = cluster_vol.z, color = cluster_factors), size = 1.2)+
  theme_bw()+
  ylab("Mean Cluster Abundance\n(Z-Scored)")+
  ggtitle("Mixed Influence Clusters")+
  theme(plot.title = element_text(size = 18, hjust = 0.5), legend.text = element_text(size = 16), legend.title = element_blank(), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), axis.title.y = element_text(size = 18))+
  #ylim(minh, maxh)+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))+
  xlab("")+
  #guides(fill=guide_legend(nrow=2,byrow=TRUE))+
  scale_color_manual(values = cols[4:8])+
  scale_fill_manual(values = c("darkgreen", "blue4"), labels = c("Peak Chlorophyll", "Peak Bacteria"))

pmix

png("mixed_clusters.png", width=8, height=5,
    units="in", res=600, pointsize=12)
pmix
dev.off()


hclust_bio <- cluster_all %>% 
  left_join(h.clust.factors.z) %>% 
  #filter(cluster_factors == "Factor A" | cluster_factors == "Factor E")
  filter(cluster_factors == "Factor A")

pbio<- ggplot()+
  geom_col(data = bio_markers, aes(x = r_date, y = biomarker_mag, fill = Event_label), width = 20000)+
  geom_line(data = hclust_bio, aes(x = r_date, y = cluster_vol.z, color = cluster_factors), size = 1.2)+
  theme_bw()+
  ylab("Mean Cluster Abundance\n(Z-Scored)")+
  ggtitle("Biogenic Influence Clusters")+
  theme(plot.title = element_text(size = 18, hjust = 0.5), legend.text = element_text(size = 16), legend.title = element_blank(), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), axis.title.y = element_text(size = 18))+
  #ylim(minh, maxh)+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))+
  xlab("")+
  #guides(fill=guide_legend(nrow=2,byrow=TRUE))+
  scale_color_manual(values = cols[3], labels = c("Biogenic A"))+
  scale_fill_manual(values = c("darkgreen", "blue4"), labels = c("Peak Chlorophyll", "Peak Bacteria"))

pbio
# check corr with diatom aggregates

png("biogenic_clusters.png", width=8, height=5,
    units="in", res=600, pointsize=12)
pbio
dev.off()


chla_hb <- bt_sum_bloom3 %>% 
  dplyr::select(r_date, Extracted_Chla, Bulk_HB_updated) %>% 
  filter(!is.na(Extracted_Chla))

max_chla <- max(chla_hb$Extracted_Chla)
max_hb <- max(chla_hb$Bulk_HB_updated)

chla_hb <- chla_hb %>% 
  mutate(chla_norm = Extracted_Chla/max_chla) %>% 
  mutate(hb_norm = Bulk_HB_updated/ max_hb)

chla_hb %>% 
  ggplot(aes(x = r_date, y = chla_norm))+
  geom_line(color = "green3", size = 1.2)+
  geom_line(aes(x = r_date, y = hb_norm), color = "blue2", size = 1.2)+
  geom_col(data = bio_markers1, aes(x = r_date, y = biomarker_mag/4, fill = Event_label), width = 20000)+
  theme_bw()+
  ylab("Normalized Concentration")+
  scale_fill_manual(values = c( "darkgreen", "blue4"), labels = c("Peak Chla", "Peak Bacteria"))+
  theme(plot.title = element_text(size = 18, hjust = 0.5), legend.text = element_text(size = 16), legend.title = element_blank(), axis.text.x = element_text(size = 18), axis.text.y = element_blank(), axis.title.y = element_text(size = 20))+
  #ylim(minh, maxh)+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))+
  xlab("")

chlaplot <- chla_hb %>% 
  ggplot(aes(x = r_date, y = chla_norm, color = "Chlorophyll A"))+
  geom_line(size = 1.2)+
  geom_line(aes(x = r_date, y = hb_norm, color = "Heterotrophic Bacteria"), size = 1.2)+
  theme_bw()+
  scale_color_manual(values = c("darkgreen", "blue4"), labels = c("Chlorophyll-a", "Heterotrophic \nBacteria"))+
  ylab("Bulk Water Concentration\n (Normalized)")+
  ggtitle("Algal Bloom Biological Indicators")+
  theme(plot.title = element_text(size = 18, hjust = 0.5), legend.text = element_text(size = 16), legend.title = element_blank(), axis.text.x = element_text(size = 18), axis.text.y = element_blank(), axis.title.y = element_text(size = 18))+
  #ylim(minh, maxh)+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))+
  xlab("")

png("Chlorophyll_hb.png", width=8, height=5,
    units="in", res=600, pointsize=12)
chlaplot
dev.off()


```
Now comparing speciated biology time series to the cluster time series

```{r}
bio_spec <- read_csv("Read_Files/Speciated_Biology_Time_Series_scaled.csv") %>% 
  mutate(r_date =    mdy_hm(SS_startdate))


pbio2<- ggplot()+
  geom_line(data = bio_spec, aes(x = r_date, y = (Diatom_Dominated_Aggregates_pct*10)-2), color = "black")+
  geom_line(data = bio_spec, aes(x = r_date, y = (Haptophytes_pct*20)-1), color = "blue")+
  #geom_line(data = bio_spec, aes(x = r_date, y = (Microzooplankton_pct*20)-1), color = "red")+
  geom_line(data = bio_spec, aes(x = r_date, y = (Diatoms_pct*6)-2), color = "red")+
  geom_line(data = hclust_bio, aes(x = r_date, y = cluster_vol.z, color = cluster_factors), size = 1.2)+
  theme_bw()+
  ylab("Mean Cluster Abundance\n(Z-Scored)")+
  ggtitle("Biogenic Influence Clusters")+
  theme(plot.title = element_text(size = 18, hjust = 0.5), legend.text = element_text(size = 16), legend.title = element_blank(), axis.text.x = element_text(size = 18), axis.text.y = element_text(size = 18), axis.title.y = element_text(size = 18))+
  #ylim(minh, maxh)+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))+
  xlab("")+
  #guides(fill=guide_legend(nrow=2,byrow=TRUE))+
  scale_color_manual(values = cols[3:4], labels = c("Biogenic A", "Biogenic B"))




pbio2

bio_corr <-M_t_analyte_withIS.q.0 %>% 
  dplyr::select(r_date, Compound.Name, amt_ng_ptnorm) %>% 
  spread(Compound.Name,amt_ng_ptnorm, fill = 0) %>% 
  left_join(bio_spec) %>% 
  filter(!is.na(SS_startdate)) %>% 
  dplyr::select(-c(r_date, SS_startdate))

bio.cor <- cor(bio_corr) 

write.csv(bio.cor, "correlation_inspection.csv")

bio.cor.info <- read_csv("correlation_inspection_ed2.csv")%>% 
  left_join(cluster_assignments) %>% 
  left_join(h.clust.factors) %>% 
  left_join(SeaScape_normalized_cumsum.q) %>% 
  left_join(compiled_comp_info) 

write.csv(bio.cor.info, "correlation_info_inspection2.csv")
```


```{r}
Hphyte.comp.pos <- bio.cor.info %>% 
  filter(quant_pct > .005) %>% 
  filter(Haptophytes > .7) %>% 
  mutate(keep = 1) 

Hphyte.comp.neg <- bio.cor.info %>% 
  filter(quant_pct > .005) %>% 
  filter(Haptophytes < -.6) %>% 
  mutate(keep = 1) 

tt <- M_t_analyte_withIS.q.0 %>% 
  left_join(Hphyte.comp.pos) %>% 
  filter(keep == 1) 

M_t_analyte_withIS.q.0 %>% 
  left_join(Hphyte.comp.pos) %>% 
  filter(keep == 1) %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm))+
  geom_line()+
  geom_line(data = bio_spec, aes(x = r_date, y = Haptophytes/1000))

Hapto.neg.plot <- M_t_analyte_withIS.q.0 %>% 
  left_join(Hphyte.comp.neg) %>% 
  filter(keep == 1) %>% 
  dplyr::select(r_date, Compound.Name, amt_ng_ptnorm, Haptophytes) %>% 
  mutate(Compound.Name = as.factor(Compound.Name))

Hapto.neg.plot %>%  
  ggplot()+
  geom_line(aes(x = r_date, y = amt_ng_ptnorm, color = Compound.Name))+
  geom_line(data = bio_spec, aes(x = r_date, y = Haptophytes/10000))


table(Hapto.neg.plot$Compound.Name)

DDA.comp.neg <- bio.cor.info %>% 
  filter(quant_pct > .005) %>% 
  filter(Diatom_Dominated_Aggregates < -.6) %>% 
  mutate(keep = 1) 

DDA.neg.plot <- M_t_analyte_withIS.q.0 %>% 
  left_join(DDA.comp.neg) %>% 
  filter(keep == 1) %>% 
  dplyr::select(r_date, Compound.Name, amt_ng_ptnorm, Haptophytes) %>% 
  mutate(Compound.Name = as.factor(Compound.Name))

DDA.neg.plot %>%  
  ggplot()+
  geom_line(aes(x = r_date, y = amt_ng_ptnorm, color = Compound.Name))+
  geom_line(data = bio_spec, aes(x = r_date, y = Diatom_Dominated_Aggregates/100000))

DDA.comp.pos <- bio.cor.info %>% 
  filter(quant_pct > .003) %>% 
  filter(Diatom_Dominated_Aggregates > .6) %>% 
  mutate(keep = 1) 

DDA.pos.plot <- M_t_analyte_withIS.q.0 %>% 
  left_join(DDA.comp.pos) %>% 
  filter(keep == 1) %>% 
  dplyr::select(r_date, Compound.Name, amt_ng_ptnorm, Haptophytes) %>% 
  mutate(Compound.Name = as.factor(Compound.Name))

DDA.pos.plot %>%  
  ggplot()+
  geom_line(aes(x = r_date, y = amt_ng_ptnorm, color = Compound.Name))+
  geom_line(data = bio_spec, aes(x = r_date, y = Diatom_Dominated_Aggregates/500000))

######

Mzoo.comp.pos <- bio.cor.info %>% 
  filter(quant_pct > .003) %>% 
  filter(Microzooplankton > .6) %>% 
  mutate(keep = 1) 

Mzoo.pos.plot <- M_t_analyte_withIS.q.0 %>% 
  left_join(Mzoo.comp.pos) %>% 
  filter(keep == 1) %>% 
  dplyr::select(r_date, Compound.Name, amt_ng_ptnorm, Haptophytes) %>% 
  mutate(Compound.Name = as.factor(Compound.Name))

Mzoo.pos.plot %>%  
  ggplot()+
  geom_line(aes(x = r_date, y = amt_ng_ptnorm, color = Compound.Name))+
  geom_line(data = bio_spec, aes(x = r_date, y = Microzooplankton/500))

Mzoo.comp.neg <- bio.cor.info %>% 
  filter(quant_pct > .001) %>% 
  filter(Microzooplankton < -.6) %>% 
  mutate(keep = 1) 

Mzoo.neg.plot <- M_t_analyte_withIS.q.0 %>% 
  left_join(Mzoo.comp.neg) %>% 
  filter(keep == 1) %>% 
  dplyr::select(r_date, Compound.Name, amt_ng_ptnorm, Haptophytes) %>% 
  mutate(Compound.Name = as.factor(Compound.Name))

Mzoo.neg.plot %>%  
  ggplot()+
  geom_line(aes(x = r_date, y = amt_ng_ptnorm, color = Compound.Name))+
  geom_line(data = bio_spec, aes(x = r_date, y = Microzooplankton/80000))


```

Now looking at knowledge of the different clusters

```{r}
knowledge_clusters <- cluster_assignments %>% 
  left_join(h.clust.factors) %>% 
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q) %>% 
  mutate(tic = 1)

knowledge_clusters %>% 
  ggplot(aes(x = cluster_factor_types, y = quant_pct, fill = Identifiable))+
  geom_col()

knowledge_clusters %>% 
  ggplot(aes(x = cluster_factor_types, y = tic, fill = Identifiable))+
  geom_col()

```






```{r}
M_t_analyte_withIS.hclust <- M_t_analyte_withIS.q %>% 
  left_join(cluster_corr_hclust) %>% 
  left_join(cluster_assignments) %>% 
  mutate(cluster_combined = ifelse(is.na(cluster), sub('.', '', best_corr), cluster)) 

hclust_factors_compinfo <- cluster_corr_hclust %>% 
  mutate(cluster_combined = ifelse(is.na(cluster), sub('.', '', best_corr), cluster)) %>% 
  right_join(compiled_comp_info)

M_t_analyte_withIS.hclust %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm, fill = as.factor(best_corr))) +
  geom_col(position = "fill")


M_t_analyte_withIS.hclust %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm, fill = as.factor(cluster))) +
  geom_col(position = "fill")

# h.clust.factors <- data.frame(cluster_combined = as.factor(c(1,2,3,4,5,6,7,8)), cluster_factors = c("Factor A", "Factor C", "Factor B", "Factor G", "Factor D", "Factor F", "Factor E", "Factor H"), cluster_factor_types = c("Anthroporenic", "Mixed", "Anthropogenic", "Biological", "Mixed", "Biological", "Mixed", "Biological"))
h.clust.factors <- h.clust.factors.z %>% 
  dplyr::rename(cluster_assigned = cluster)


M_t_analyte_withIS.hclust <- M_t_analyte_withIS.hclust %>% 
  left_join(h.clust.factors)
  

carbon_pool <- M_t_analyte_withIS.hclust %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm, fill = cluster_factor_types)) +
  geom_col(position = "fill")+
  theme_bw()+
  xlab("")+
  ylab("Mass Fraction")+
  ggtitle("Submicron Sea Spray Aerosol \n Carbon Pool Dynamics")+
  theme(plot.title = element_text(size = 18, hjust = .5), legend.text = element_text(size = 14), legend.title=element_text(size=14), axis.text.x = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title.y = element_text(size = 16))+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))
  

carbon_pool

png("carbon_pool.png", width=8, height=5,
    units="in", res=600, pointsize=12)
carbon_pool
dev.off()

carbon_pool_nodiiso <- M_t_analyte_withIS.hclust %>% 
  filter(Compound.Name != "20200803_1535_blob_745_") %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm, fill = cluster_factor_types)) +
  geom_col(position = "fill")+
  theme_bw()+
  xlab("")+
  ylab("Mass Fraction")+
  ggtitle("Submicron Sea Spray Aerosol \n Carbon Pool Dynamics")+
  theme(plot.title = element_text(size = 18, hjust = .5), legend.text = element_text(size = 14), legend.title=element_text(size=14), axis.text.x = element_text(size = 14), axis.text.y = element_text(size = 14), axis.title.y = element_text(size = 16))+
  scale_x_datetime(date_breaks = "6 days", labels = date_format("%b %d"))
  


carbon_pool_nodiiso

M_t_analyte_withIS.hclust %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm, fill = cluster_factor_types)) +
  geom_col(position = "stack")

M_t_analyte_withIS.hclust %>% 
  filter(Compound.Name != "20200803_1535_blob_745_") %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm, fill = cluster_factor_types)) +
  geom_col(position = "stack")
```


```{r}
#BTZ check
M_t_analyte_withIS.hclust %>% 
  filter(Compound.Name == "20200803_1535_blob_958_") %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm))+
  geom_point()

M_t_analyte_withIS.q %>% 
  filter(Compound.Name == "20200803_1535_blob_958_") %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm))+
  geom_point()

M_t_analyte_withIS.q %>% 
  filter(Compound.Name == "20200803_1535_blob_958_") %>% 
  ggplot(aes(x = r_date, y = vol_is_normnorm_ptnorm))+
  geom_point()

M_t_analyte_withIS.q %>% 
  filter(Compound.Name == "20200803_1535_blob_958_") %>% 
  ggplot(aes(x = r_date, y = vol_is_rawnorm_ptnorm))+
  geom_point()

M_t_analyte_withIS_smoothed %>% 
  filter(Compound.Name == "20200803_1535_blob_958_") %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm_smooth))+
  geom_point()



cluster_corr_hclust.5 <- cluster_corr_hclust %>% 
  filter(best_corr == "F5") %>% 
  left_join(compiled_comp_info)

# diiso check

diiso_check <- M_t_analyte_withIS.q %>% 
  filter(Compound.Name == "20200803_1535_blob_745_")

diiso_check %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm))+
  geom_line()

diiso_check %>% 
  ggplot(aes(x = r_date, y = vol_is_normnorm_ptnorm))+
  geom_line()

diiso_check %>% 
  ggplot(aes(x = r_date, y = vol_is_rawnorm_ptnorm))+
  geom_line()

diiso_check %>% 
  ggplot(aes(x = r_date, y = IS_mean_norm))+
  geom_line()

diiso_check %>% 
  ggplot(aes(x = r_date, y = Volume))+
  geom_line()
```
Inspecting the unclustered compounds
```{r}

unclustered <- M_t_analyte_withIS.hclust %>% 
  filter(is.na(cluster_factor_types)) %>% 
  left_join(SeaScape_normalized_cumsum.q) %>% 
  arrange(desc(quant_pct))

table(unclustered$Compound.Name)


write.csv(unclustered, "inspect_unclustered.csv")
```


What is actually in each cluster
```{r}

c1_bio1 <- cluster_assignments %>% 
  filter(cluster_assigned == 1) %>% 
  left_join(Analyte_positions) %>% 
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

c2_anthro1 <- cluster_assignments %>% 
  filter(cluster_assigned == 2) %>%   
  left_join(Analyte_positions) %>% 
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

c3 <- cluster_assignments %>% 
  filter(cluster_assigned == 3) %>%
  left_join(Analyte_positions) %>%
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

c4 <- cluster_assignments %>% 
  filter(cluster_assigned == 4) %>% 
  left_join(Analyte_positions) %>%
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

c5_mixed_interesting <- cluster_assignments %>% 
  filter(cluster_assigned == 5) %>% 
  left_join(Analyte_positions) %>%
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

c6_anthro2 <- cluster_assignments %>% 
  filter(cluster_assigned == 6) %>% 
  left_join(Analyte_positions) %>%
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

c7 <- cluster_assignments %>% 
  filter(cluster_assigned == 7) %>% 
  left_join(Analyte_positions) %>%
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

c8 <- cluster_assignments %>% 
  filter(cluster_assigned == 8) %>% 
  left_join(Analyte_positions) %>%
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

call <- cluster_assignments %>% 
  left_join(Analyte_positions) %>%
  left_join(compiled_comp_info) %>% 
  left_join(SeaScape_normalized_cumsum.q)

call %>% 
  ggplot(aes(x = LRI.I, y = RI2, color = as.factor(cluster_assigned)))+
  geom_point()

c1_bio1 %>% 
  ggplot(aes(x = quantcumsum, y = Library.Match.Factor_NISTmain))+
  geom_point()

c2_anthro1 %>% 
  ggplot(aes(x = quantcumsum, y = Library.Match.Factor_NISTmain))+
  geom_point()


```




```{r}
for(i in 1:nrow(cluster_corr_hclust.5)){
  cc <- cluster_corr_hclust.5$Compound.Name[i]
  
  fff <- M_t_analyte_withIS %>% 
    filter(Compound.Name == cc) %>% 
    ggplot(aes(x = r_date, y = amt_ng_ptnorm, color = Compound.Name))+
    geom_line()
  
  print(fff)
  
}


```


```{r}

summary(SeaScape_normalized_cumsum$isnormnormptnorm_cumsum)

M_t_analyte_withIS.hclust %>% 
  left_join(compiled_comp_info, by = "Compound.Name") %>% 
  left_join(SeaScape_normalized_cumsum) %>% 
  left_join(h.clust.factors) %>% 
  filter(isnormnormptnorm_cumsum > 8562) %>% 
  ggplot(aes(x = cluster_factors, y = Library.Match.Factor_NISTmain, fill = cluster_factors))+
  geom_violin()

ttt <- M_t_analyte_withIS.hclust %>% 
  left_join(compiled_comp_info, by = "Compound.Name") %>% 
  left_join(SeaScape_normalized_cumsum_cumulative) %>% 
  left_join(h.clust.factors) %>% 
  filter(isnormnorm_ptnorm_pct_cumulative < .9) %>% 
  group_by(Compound.Name, cluster_factors) %>% 
  summarise(la = 1)

table(ttt$cluster_factors)

M_t_analyte_withIS.hclust %>% 
  left_join(compiled_comp_info, by = "Compound.Name") %>% 
  left_join(SeaScape_normalized_cumsum_cumulative) %>% 
  left_join(h.clust.factors) %>% 
  filter(isnormnorm_ptnorm_pct_cumulative < .9) %>% 
  ggplot(aes(x = cluster_factors, y = Library.Match.Factor_NISTmain, fill = cluster_factors))+
  geom_boxplot()+
  theme_bw()+
  ylab("NIST Mass Spectral\nMatch Factor")+
  xlab("")+
  theme(axis.text.x = element_text(size = 16, angle = -45, vjust = .2, hjust = .5), axis.text.y = element_text(size = 16), axis.title.y = element_text(size = 18))

library("DescTools")

NIST_summaries.hclust <- M_t_analyte_withIS.hclust %>% 
  left_join(compiled_comp_info, by = "Compound.Name") %>% 
  left_join(SeaScape_normalized_cumsum_cumulative) %>% 
  left_join(h.clust.factors) %>% 
  filter(isnormnorm_ptnorm_pct_cumulative < .9) %>% 
  mutate(rounded_nist= RoundTo(Library.Match.Factor_NISTmain, 10)) %>% 
  group_by(rounded_nist, cluster_factors) %>% 
  summarise(nist_normalized_signal_pct = sum(isnormnormptnorm_pct))

cumulative_signal_byfactor <- NIST_summaries.hclust %>% 
  group_by(cluster_factors) %>% 
  summarise(total_factor_signal = sum(nist_normalized_signal_pct))

NIST_summaries.hclust <- NIST_summaries.hclust %>% 
  left_join(cumulative_signal_byfactor) %>% 
  mutate(normalized_nistbinned_signal = nist_normalized_signal_pct / total_factor_signal)

NIST_summaries.hclust %>% 
  ggplot(aes(x = rounded_nist, y = nist_normalized_signal_pct, fill = cluster_factors))+
  geom_col()

# M_t_analyte_withIS.hclust %>% 
#   left_join(compiled_comp_info, by = "Compound.Name") %>% 
#   left_join(SeaScape_normalized_cumsum_cumulative) %>% 
#   left_join(h.clust.factors) %>% 
#   filter(isnormnorm_ptnorm_pct_cumulative < .9) %>% 
#   mutate(rounded_nist= RoundTo(Library.Match.Factor_NISTmain, 25))
#   ggplot(aes(x = log(isnormnormptnorm_pct), y = Library.Match.Factor_NISTmain, color = cluster_factors))+
#   geom_point()

M_t_analyte_withIS.hclust %>% 
  left_join(compiled_comp_info, by = "Compound.Name") %>% 
  ggplot(aes(x = cluster_combined, y = LRI.I.x, fill = cluster_combined))+
  geom_violin()

M_t_analyte_withIS.hclust %>% 
  left_join(compiled_comp_info, by = "Compound.Name") %>% 
  left_join(SeaScape_normalized_cumsum) %>% 
  ggplot(aes(x = cluster_combined, y = LRI.I.x, fill = cluster_combined))+
  geom_violin()

# personal care products
M_t_analyte_withIS.hclust.1 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 1)

# early perturbed- possibly bio related, spiky
M_t_analyte_withIS.hclust.2 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 2)

# possibly bio related decreases then increasesan
M_t_analyte_withIS.hclust.3 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 3)

# anthro biodegrades- oil typical
M_t_analyte_withIS.hclust.4 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 4)

# lots of s containing things- interesting
M_t_analyte_withIS.hclust.5 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 5)


#biolog accumulating- breakdown products
M_t_analyte_withIS.hclust.6 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 6)

# biogenic things
M_t_analyte_withIS.hclust.7 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 7)

# more biogenic things
M_t_analyte_withIS.hclust.8 <- M_t_analyte_withIS.hclust %>%
  left_join(compiled_comp_info, by = "Compound.Name") %>%
  filter(cluster_combined == 8)



```


```{r}

clusters_compID <- cluster_corr_infor %>% 
  mutate(cluster_combined = ifelse(is.na(cluster), sub('.', '', best_corr), cluster)) %>% 
  left_join(h.clust.factors) %>% 
  left_join(SeaScape_normalized_cumsum)

# personal care products, homosalate important
clustersAid <- clusters_compID %>% 
  filter(cluster_factors== "Factor A") %>% 
  arrange(desc(isnormnormptnorm_cumsum))

# dimethylheptadecane, oils
clustersBid <- clusters_compID %>% 
  filter(cluster_factors== "Factor B") %>% 
  arrange(desc(isnormnormptnorm_cumsum))

# palmitic acid, maybe contamination
clustersCid <- clusters_compID %>% 
  filter(cluster_factors== "Factor C") %>% 
  arrange(desc(isnormnormptnorm_cumsum))

# definitely a mix of things
clustersDid <- clusters_compID %>% 
  filter(cluster_factors== "Factor D") %>% 
  arrange(desc(isnormnormptnorm_cumsum))

# total mystery but theres not much of it so qho cares
clustersEid <- clusters_compID %>% 
  filter(cluster_factors== "Factor E") %>% 
  arrange(desc(isnormnormptnorm_cumsum))



# a lot of this looks antho tbh, but gonna focus on 	Cyclooctasiloxane, hexadecamethyl-, which is reported in marine cyanobacteria and looks biogenic from time series
clustersFid <- clusters_compID %>% 
  filter(cluster_factors== "Factor F") %>% 
  arrange(desc(isnormnormptnorm_cumsum))

M_t_analyte_withIS_smoothed %>% 
  filter(Compound.Name == "20200803_1535_blob_453_") %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm_smooth))+
  geom_line()

M_t_analyte_withIS_smoothed %>% 
  filter(Compound.Name == "20200803_1535_blob_23_fb") %>% 
  ggplot(aes(x = r_date, y = amt_ng_ptnorm_smooth))+
  geom_line()

M_t_analyte_withIS_smoothed %>% 
  filter(Compound.Name == "20200803_0949_blob_786_") %>% 
  ggplot(aes(x = r_date, y = vol_is_normnorm_ptnorm_smooth))+
  geom_line()

# dimethyl quinoline and trimethyl quinoline, previously reported intercellylar algae components
clustersGid <- clusters_compID %>% 
  filter(cluster_factors== "Factor G") %>% 
  arrange(desc(isnormnormptnorm_cumsum))

# alcohol components of previously reported macroalgae
# also linalool oxide, reported in red algae
clustersHid <- clusters_compID %>% 
  filter(cluster_factors== "Factor H") %>% 
  arrange(desc(isnormnormptnorm_cumsum))

M_t_analyte_withIS_smoothed %>% 
  filter(Compound.Name == "20200803_0949_blob_715_oil") %>% 
  ggplot(aes(x = r_date, y = vol_is_normnorm_ptnorm_smooth))+
  geom_line()




```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
